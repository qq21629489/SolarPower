{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant\n",
    "# 0~0.7 training\n",
    "# 0.7~0.9 testing\n",
    "# 0.9~1.0 validation\n",
    "TRAIN_THRESH = 0.7\n",
    "TEST_THRESH = 0.9\n",
    "REF_SIZE = 24 * 7 # for one week\n",
    "PREDICT_SIZE = 1 # for one day\n",
    "BATCH_SIZE = 128\n",
    "PATIENCE = 10\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file ./training_data\\target0.csv (1/50)\n",
      "loading file ./training_data\\target1.csv (2/50)\n",
      "loading file ./training_data\\target10.csv (3/50)\n",
      "loading file ./training_data\\target11.csv (4/50)\n",
      "loading file ./training_data\\target12.csv (5/50)\n",
      "loading file ./training_data\\target13.csv (6/50)\n",
      "loading file ./training_data\\target14.csv (7/50)\n",
      "loading file ./training_data\\target15.csv (8/50)\n",
      "loading file ./training_data\\target16.csv (9/50)\n",
      "loading file ./training_data\\target17.csv (10/50)\n",
      "loading file ./training_data\\target18.csv (11/50)\n",
      "loading file ./training_data\\target19.csv (12/50)\n",
      "loading file ./training_data\\target2.csv (13/50)\n",
      "loading file ./training_data\\target20.csv (14/50)\n",
      "loading file ./training_data\\target21.csv (15/50)\n",
      "loading file ./training_data\\target22.csv (16/50)\n",
      "loading file ./training_data\\target23.csv (17/50)\n",
      "loading file ./training_data\\target24.csv (18/50)\n",
      "loading file ./training_data\\target25.csv (19/50)\n",
      "loading file ./training_data\\target26.csv (20/50)\n",
      "loading file ./training_data\\target27.csv (21/50)\n",
      "loading file ./training_data\\target28.csv (22/50)\n",
      "loading file ./training_data\\target29.csv (23/50)\n",
      "loading file ./training_data\\target3.csv (24/50)\n",
      "loading file ./training_data\\target30.csv (25/50)\n",
      "loading file ./training_data\\target31.csv (26/50)\n",
      "loading file ./training_data\\target32.csv (27/50)\n",
      "loading file ./training_data\\target33.csv (28/50)\n",
      "loading file ./training_data\\target34.csv (29/50)\n",
      "loading file ./training_data\\target35.csv (30/50)\n",
      "loading file ./training_data\\target36.csv (31/50)\n",
      "loading file ./training_data\\target37.csv (32/50)\n",
      "loading file ./training_data\\target38.csv (33/50)\n",
      "loading file ./training_data\\target39.csv (34/50)\n",
      "loading file ./training_data\\target4.csv (35/50)\n",
      "loading file ./training_data\\target40.csv (36/50)\n",
      "loading file ./training_data\\target41.csv (37/50)\n",
      "loading file ./training_data\\target42.csv (38/50)\n",
      "loading file ./training_data\\target43.csv (39/50)\n",
      "loading file ./training_data\\target44.csv (40/50)\n",
      "loading file ./training_data\\target45.csv (41/50)\n",
      "loading file ./training_data\\target46.csv (42/50)\n",
      "loading file ./training_data\\target47.csv (43/50)\n",
      "loading file ./training_data\\target48.csv (44/50)\n",
      "loading file ./training_data\\target49.csv (45/50)\n",
      "loading file ./training_data\\target5.csv (46/50)\n",
      "loading file ./training_data\\target6.csv (47/50)\n",
      "loading file ./training_data\\target7.csv (48/50)\n",
      "loading file ./training_data\\target8.csv (49/50)\n",
      "loading file ./training_data\\target9.csv (50/50)\n",
      "      generation  consumption  month  day  hour\n",
      "0           0.00         0.05      1    1     0\n",
      "1           0.00         1.52      1    1     1\n",
      "2           0.01         1.09      1    1     2\n",
      "3           0.00         0.95      1    1     3\n",
      "4           0.00         0.75      1    1     4\n",
      "...          ...          ...    ...  ...   ...\n",
      "5827        0.03         3.42      8   31    19\n",
      "5828        0.00         3.55      8   31    20\n",
      "5829        0.00         3.07      8   31    21\n",
      "5830        0.00         2.34      8   31    22\n",
      "5831        0.00         2.04      8   31    23\n",
      "\n",
      "[5832 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def loadData():\n",
    "    paths = glob.glob(r'./training_data/*.csv')\n",
    "    datas = []\n",
    "    max_dict = {'generation':-1.0, 'consumption':-1.0}\n",
    "    \n",
    "    for i in range(len(paths)):\n",
    "        print('loading file {} ({}/{})'.format(paths[i], i + 1, len(paths)))\n",
    "        df = pd.read_csv(paths[i])\n",
    "        \n",
    "        g_max, c_max = df['generation'].max(), df['consumption'].max()\n",
    "        max_dict['generation'] = g_max if g_max > max_dict['generation'] else max_dict['generation']\n",
    "        max_dict['consumption'] = c_max if c_max > max_dict['consumption'] else max_dict['consumption']\n",
    "        \n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df['month'] = df['time'].dt.month\n",
    "        df['day'] = df['time'].dt.day\n",
    "        df['hour'] = df['time'].dt.hour\n",
    "        df = df.drop(['time'], axis=1)\n",
    "        datas.append(df)\n",
    "    # print(datas)\n",
    "    # print(max_dict)\n",
    "    return datas, max_dict\n",
    "\n",
    "datas, max_dict = loadData()\n",
    "print(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setXY(datas, ref_size, predict_size, type_='generation'):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for index, data in enumerate(datas):\n",
    "        for j in range(len(data) - ref_size -  predict_size):\n",
    "            # if type_ == 'generation':\n",
    "            #     data.drop('consumption', axis=1)\n",
    "            # elif type_ == 'consumption':\n",
    "            #     data.drop('generation', axis=1)\n",
    "            \n",
    "            x.append(np.array(data.iloc[j: j + ref_size]))\n",
    "            y.append(np.array(data.iloc[j + ref_size: j + ref_size + predict_size][type_]))\n",
    "        print('{} done'.format(index))\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    np.random.seed(int(time.time()))\n",
    "    randomList = np.arange(x.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return x[randomList], y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLSTM(input_shape, output_shape):\n",
    "    # model = Sequential()\n",
    "    # model.add(LSTM(units=900, return_sequences = True, kernel_initializer = 'glorot_uniform', input_shape = (input_shape[1], input_shape[2])))\n",
    "    # model.add(Dropout(0.3))\n",
    "    # model.add(LSTM(units = 900, kernel_initializer = 'glorot_uniform', return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 300, kernel_initializer = 'glorot_uniform', return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 300, kernel_initializer = 'glorot_uniform', return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 300, kernel_initializer = 'glorot_uniform', return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units = 300, kernel_initializer = 'glorot_uniform'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(units = output_shape))\n",
    "    # model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "    # model.summary()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(input_shape[1], input_shape[2]), return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a second LSTM layer and some Dropout regularization\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a second LSTM layer and some Dropout regularization\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a fourth LSTM layer and some Dropout regularization\n",
    "    model.add(TimeDistributed(Dense(units = 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_shape))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mse'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "# lstm_model_c = buildLSTM(train_x.shape, PREDICT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 done\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 done\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 done\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "(283150, 168, 5)\n",
      "(283150, 1)\n",
      "(198205, 168, 5) (198205, 1)\n",
      "(56630, 168, 5) (56630, 1)\n",
      "(28315, 168, 5) (28315, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = setXY(datas, REF_SIZE, PREDICT_SIZE)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split train test\n",
    "# 0~0.7 training\n",
    "# 0.7~0.9 testing\n",
    "# 0.9~1.0 validation\n",
    "train_x, train_y = shuffle(x[:int(x.shape[0] * TRAIN_THRESH)], y[:int(y.shape[0] * TRAIN_THRESH)])\n",
    "test_x, test_y   = shuffle(x[int(x.shape[0] * TRAIN_THRESH): int(y.shape[0] * TEST_THRESH)], y[int(y.shape[0] * TRAIN_THRESH): int(y.shape[0] * TEST_THRESH)])\n",
    "val_x, val_y     = shuffle(x[int(x.shape[0] * TEST_THRESH):], y[int(y.shape[0] * TEST_THRESH):])\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 168, 64)           17920     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 168, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 168, 64)           33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 168, 64)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 168, 64)           33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 168, 64)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 168, 1)           65        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 168)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               86528     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,074\n",
      "Trainable params: 171,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1549/1549 [==============================] - 96s 55ms/step - loss: 0.1535 - mse: 0.1535 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 2/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0741 - mse: 0.0741 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 3/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 4/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 5/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 7/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 8/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 9/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11/100\n",
      "1549/1549 [==============================] - 86s 55ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12/100\n",
      "1549/1549 [==============================] - 84s 55ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 14/100\n",
      "1549/1549 [==============================] - 84s 55ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 15/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 16/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 17/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 18/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 19/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 20/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 21/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 22/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 23/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 24/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 25/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 26/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 27/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 28/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 29/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 30/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 31/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 32/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 33/100\n",
      "1549/1549 [==============================] - 86s 56ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 34/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 35/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 36/100\n",
      "1549/1549 [==============================] - 86s 55ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 37/100\n",
      "1549/1549 [==============================] - 86s 55ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 38/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 39/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 40/100\n",
      "1549/1549 [==============================] - 86s 55ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 41/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 42/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 43/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 44/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 45/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 46/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 47/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 48/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 49/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 50/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 51/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 52/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 53/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 54/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 55/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 56/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 57/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 58/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 59/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 60/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 61/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 62/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 63/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 64/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 65/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 66/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 67/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 68/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 69/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0067 - val_mse: 0.0067ss: - ETA: 1s \n",
      "Epoch 70/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 71/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 72/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 73/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 74/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 75/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 00075: early stopping\n"
     ]
    }
   ],
   "source": [
    "lstm_modelG = buildLSTM(train_x.shape, PREDICT_SIZE)\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=PATIENCE, verbose=1, mode='min')\n",
    "historyG = lstm_modelG.fit(train_x, train_y, verbose=1, callbacks=[early_stopping], validation_data=(val_x, val_y), batch_size=BATCH_SIZE, epochs=EPOCH)\n",
    "\n",
    "lstm_modelG.save('modeG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 done\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 done\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 done\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "(283150, 168, 5)\n",
      "(283150, 1)\n",
      "(198205, 168, 5) (198205, 1)\n",
      "(56630, 168, 5) (56630, 1)\n",
      "(28315, 168, 5) (28315, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = setXY(datas, REF_SIZE, PREDICT_SIZE, type_='consumption')\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split train test\n",
    "# 0~0.7 training\n",
    "# 0.7~0.9 testing\n",
    "# 0.9~1.0 validation\n",
    "train_x, train_y = shuffle(x[:int(x.shape[0] * TRAIN_THRESH)], y[:int(y.shape[0] * TRAIN_THRESH)])\n",
    "test_x, test_y   = shuffle(x[int(x.shape[0] * TRAIN_THRESH): int(y.shape[0] * TEST_THRESH)], y[int(y.shape[0] * TRAIN_THRESH): int(y.shape[0] * TEST_THRESH)])\n",
    "val_x, val_y     = shuffle(x[int(x.shape[0] * TEST_THRESH):], y[int(y.shape[0] * TEST_THRESH):])\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 168, 64)           17920     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 168, 64)           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 168, 64)           33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 168, 64)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 168, 64)           33024     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 168, 64)           0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 168, 1)           65        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               86528     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,074\n",
      "Trainable params: 171,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1549/1549 [==============================] - 90s 54ms/step - loss: 0.5817 - mse: 0.5817 - val_loss: 0.4545 - val_mse: 0.4545\n",
      "Epoch 2/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.3699 - mse: 0.3699 - val_loss: 0.3996 - val_mse: 0.3996\n",
      "Epoch 3/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.3408 - mse: 0.3408 - val_loss: 0.3862 - val_mse: 0.3862\n",
      "Epoch 4/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.3181 - mse: 0.3181 - val_loss: 0.3616 - val_mse: 0.3616\n",
      "Epoch 5/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.2860 - mse: 0.2860 - val_loss: 0.3238 - val_mse: 0.3238\n",
      "Epoch 6/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.2587 - mse: 0.2587 - val_loss: 0.2835 - val_mse: 0.2835\n",
      "Epoch 7/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.2349 - mse: 0.2349 - val_loss: 0.2800 - val_mse: 0.2800\n",
      "Epoch 8/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2506 - val_mse: 0.2506\n",
      "Epoch 9/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.2003 - mse: 0.2003 - val_loss: 0.2358 - val_mse: 0.2358\n",
      "Epoch 10/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1901 - mse: 0.1901 - val_loss: 0.2254 - val_mse: 0.2254\n",
      "Epoch 11/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.1808 - mse: 0.1808 - val_loss: 0.2144 - val_mse: 0.2144\n",
      "Epoch 12/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1729 - mse: 0.1729 - val_loss: 0.2101 - val_mse: 0.2101\n",
      "Epoch 13/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1670 - mse: 0.1670 - val_loss: 0.2074 - val_mse: 0.2074\n",
      "Epoch 14/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1605 - mse: 0.1605 - val_loss: 0.1883 - val_mse: 0.1883\n",
      "Epoch 15/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1557 - mse: 0.1557 - val_loss: 0.1895 - val_mse: 0.1895\n",
      "Epoch 16/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.1513 - mse: 0.1513 - val_loss: 0.1867 - val_mse: 0.1867\n",
      "Epoch 17/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1475 - mse: 0.1475 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 18/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1441 - mse: 0.1441 - val_loss: 0.1737 - val_mse: 0.1737\n",
      "Epoch 19/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1416 - mse: 0.1416 - val_loss: 0.1750 - val_mse: 0.1750\n",
      "Epoch 20/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.1378 - mse: 0.1378 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 21/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1352 - mse: 0.1352 - val_loss: 0.1655 - val_mse: 0.1655\n",
      "Epoch 22/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1690 - val_mse: 0.1690\n",
      "Epoch 23/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 0.1590 - val_mse: 0.1590\n",
      "Epoch 24/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.1284 - mse: 0.1284 - val_loss: 0.1688 - val_mse: 0.1688\n",
      "Epoch 25/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 0.1574 - val_mse: 0.1574\n",
      "Epoch 26/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 0.1564 - val_mse: 0.1564\n",
      "Epoch 27/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1606 - val_mse: 0.1606\n",
      "Epoch 28/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.1515 - val_mse: 0.1515\n",
      "Epoch 29/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 0.1507 - val_mse: 0.1507\n",
      "Epoch 30/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1167 - mse: 0.1167 - val_loss: 0.1546 - val_mse: 0.1546\n",
      "Epoch 31/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 0.1508 - val_mse: 0.1508\n",
      "Epoch 32/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 0.1489 - val_mse: 0.1489\n",
      "Epoch 33/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 0.1431 - val_mse: 0.1431\n",
      "Epoch 34/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.1412 - val_mse: 0.1412\n",
      "Epoch 35/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 36/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 0.1466 - val_mse: 0.1466\n",
      "Epoch 37/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1077 - mse: 0.1077 - val_loss: 0.1405 - val_mse: 0.1405\n",
      "Epoch 38/100\n",
      "1549/1549 [==============================] - 85s 55ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 0.1401 - val_mse: 0.1401\n",
      "Epoch 39/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 40/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.1358 - val_mse: 0.1358\n",
      "Epoch 41/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 42/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 43/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.1407 - val_mse: 0.1407\n",
      "Epoch 44/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.1344 - val_mse: 0.1344\n",
      "Epoch 45/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.1342 - val_mse: 0.1342\n",
      "Epoch 46/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.1000 - mse: 0.1000 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 47/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.1334 - val_mse: 0.1334\n",
      "Epoch 48/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.1460 - val_mse: 0.1460\n",
      "Epoch 49/100\n",
      "1549/1549 [==============================] - 84s 54ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 50/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 0.1307 - val_mse: 0.1307\n",
      "Epoch 51/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.1330 - val_mse: 0.1330\n",
      "Epoch 52/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.1309 - val_mse: 0.1309\n",
      "Epoch 53/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.1270 - val_mse: 0.1270\n",
      "Epoch 54/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.1327 - val_mse: 0.1327\n",
      "Epoch 55/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 56/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 0.1498 - val_mse: 0.1498\n",
      "Epoch 57/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.1325 - val_mse: 0.1325\n",
      "Epoch 58/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 0.1272 - val_mse: 0.1272\n",
      "Epoch 59/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0906 - mse: 0.0906 - val_loss: 0.1309 - val_mse: 0.1309\n",
      "Epoch 60/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.1272 - val_mse: 0.1272\n",
      "Epoch 61/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.1261 - val_mse: 0.1261\n",
      "Epoch 62/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.1276 - val_mse: 0.1276\n",
      "Epoch 63/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 0.1280 - val_mse: 0.1280\n",
      "Epoch 64/100\n",
      "1549/1549 [==============================] - 83s 53ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.1256 - val_mse: 0.1256\n",
      "Epoch 65/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 0.1254 - val_mse: 0.1254\n",
      "Epoch 66/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.1295 - val_mse: 0.1295\n",
      "Epoch 67/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.1333 - val_mse: 0.1333\n",
      "Epoch 68/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 0.1217 - val_mse: 0.1217\n",
      "Epoch 69/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.1310 - val_mse: 0.1310\n",
      "Epoch 70/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.1267 - val_mse: 0.1267\n",
      "Epoch 71/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.1289 - val_mse: 0.1289\n",
      "Epoch 72/100\n",
      "1549/1549 [==============================] - 81s 53ms/step - loss: 0.0846 - mse: 0.0846 - val_loss: 0.1224 - val_mse: 0.1224\n",
      "Epoch 73/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.1232 - val_mse: 0.1232\n",
      "Epoch 74/100\n",
      "1549/1549 [==============================] - 82s 53ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.1220 - val_mse: 0.1220\n",
      "Epoch 75/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 76/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.1221 - val_mse: 0.1221\n",
      "Epoch 77/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.1232 - val_mse: 0.1232\n",
      "Epoch 78/100\n",
      "1549/1549 [==============================] - 83s 54ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 00078: early stopping\n"
     ]
    }
   ],
   "source": [
    "lstm_modelC = buildLSTM(train_x.shape, PREDICT_SIZE)\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=PATIENCE, verbose=1, mode='min')\n",
    "historyC = lstm_modelC.fit(train_x, train_y, verbose=1, callbacks=[early_stopping], validation_data=(val_x, val_y), batch_size=BATCH_SIZE, epochs=EPOCH)\n",
    "\n",
    "lstm_modelC.save('modeC.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPredictData():\n",
    "    dfG = pd.read_csv('sample_data\\generation.csv')\n",
    "    dfC = pd.read_csv('sample_data\\consumption.csv')\n",
    "    \n",
    "    df = pd.merge(dfG, dfC, on='time')\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['day'] = df['time'].dt.dayofweek\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df = df.drop(['time'], axis=1)\n",
    "    # print(datas)\n",
    "    # print(max_dict)\n",
    "    return df\n",
    "\n",
    "data_to_predict = loadPredictData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-05 00:00:00 done\n",
      "2018-08-05 01:00:00 done\n",
      "2018-08-05 02:00:00 done\n",
      "2018-08-05 03:00:00 done\n",
      "2018-08-05 04:00:00 done\n",
      "2018-08-05 05:00:00 done\n",
      "2018-08-05 06:00:00 done\n",
      "2018-08-05 07:00:00 done\n",
      "2018-08-05 08:00:00 done\n",
      "2018-08-05 09:00:00 done\n",
      "2018-08-05 10:00:00 done\n",
      "2018-08-05 11:00:00 done\n",
      "2018-08-05 12:00:00 done\n",
      "2018-08-05 13:00:00 done\n",
      "2018-08-05 14:00:00 done\n",
      "2018-08-05 15:00:00 done\n",
      "2018-08-05 16:00:00 done\n",
      "2018-08-05 17:00:00 done\n",
      "2018-08-05 18:00:00 done\n",
      "2018-08-05 19:00:00 done\n",
      "2018-08-05 20:00:00 done\n",
      "2018-08-05 21:00:00 done\n",
      "2018-08-05 22:00:00 done\n",
      "2018-08-05 23:00:00 done\n",
      "result G: \n",
      "[0.007454425096511841, 0.011010423302650452, 0.014587655663490295, 0.012068361043930054, 0.010283604264259338, 0.008225038647651672, 0.02036626636981964, 0.11143942922353745, 0.6640895009040833, 1.7087124586105347, 2.5800700187683105, 3.390260696411133, 3.8186681270599365, 3.736785888671875, 3.6844940185546875, 3.2367734909057617, 2.482016086578369, 1.4789804220199585, 0.48836737871170044, 0.09540407359600067, 0.014725789427757263, 0.007164940237998962, 0.007570639252662659, 0.009823217988014221]\n",
      "====================\n",
      "result C: \n",
      "[2.0349221229553223, 2.310868263244629, 2.527947425842285, 1.9704489707946777, 2.707611083984375, 3.127387285232544, 2.142369270324707, 2.0020384788513184, 1.4365193843841553, 2.081331253051758, 2.500291109085083, 2.4399163722991943, 2.9848427772521973, 3.5208895206451416, 3.569493293762207, 3.2687344551086426, 4.291411876678467, 3.3484363555908203, 3.5534956455230713, 3.4432592391967773, 3.2256476879119873, 3.3571996688842773, 2.5035321712493896, 1.675137996673584]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def Predict(data, last_date):\n",
    "    trained_modelG = keras.models.load_model('modeG.h5')\n",
    "    trained_modelC = keras.models.load_model('modeC.h5')\n",
    "    \n",
    "    date = datetime.datetime(2018, last_date[0], last_date[1], last_date[2], 0, 0)\n",
    "    \n",
    "    resultG = []\n",
    "    resultC = []\n",
    "    \n",
    "    SIZE = 24 # 1 day / 24 hours\n",
    "    for _ in range(SIZE):\n",
    "        predictG = trained_modelG.predict(data)[0]\n",
    "        predictC = trained_modelC.predict(data)[0]\n",
    "        \n",
    "        \n",
    "        resultG.append(float(predictG))\n",
    "        resultC.append(float(predictC))\n",
    "        \n",
    "        date += datetime.timedelta(hours=1)\n",
    "        \n",
    "        tmp = [predictG[0], predictC[0], date.month, date.day, date.hour]\n",
    "        \n",
    "        data = np.array([np.vstack((data[0], tmp))[1:]])\n",
    "        \n",
    "        print('{} done'.format(date))\n",
    "        \n",
    "    return resultG, resultC\n",
    "\n",
    "last_month = data_to_predict['month'].iloc[-1]\n",
    "last_day = data_to_predict['day'].iloc[-1]\n",
    "last_hour = data_to_predict['hour'].iloc[-1]\n",
    "\n",
    "resultG, resultC = Predict(np.array([data_to_predict.values]), (last_month, last_day, last_hour))\n",
    "print('result G: ')\n",
    "print(resultG)\n",
    "print('='*20)\n",
    "print('result C: ')\n",
    "print(resultC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb4cdb330c5ea7232880705c0e79ad22649a7c708042624124f8ff95c4dc218f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
